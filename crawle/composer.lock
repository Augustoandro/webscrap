{
    "_readme": [
        "This file locks the dependencies of your project to a known state",
        "Read more about it at https://getcomposer.org/doc/01-basic-usage.md#installing-dependencies",
        "This file is @generated automatically"
    ],
    "content-hash": "51344b157b5a9d3a02cb86c6f1749762",
    "packages": [
        {
            "name": "t1gor/robots-txt-parser",
            "version": "dev-master",
            "source": {
                "type": "git",
                "url": "https://github.com/t1gor/Robots.txt-Parser-Class.git",
                "reference": "7ff08da5625fb4f72d17b1528c60aadb184e9e68"
            },
            "dist": {
                "type": "zip",
                "url": "https://api.github.com/repos/t1gor/Robots.txt-Parser-Class/zipball/7ff08da5625fb4f72d17b1528c60aadb184e9e68",
                "reference": "7ff08da5625fb4f72d17b1528c60aadb184e9e68",
                "shasum": ""
            },
            "require": {
                "ext-mbstring": "*",
                "php": ">=5.5.0",
                "vipnytt/useragentparser": "^1.0"
            },
            "require-dev": {
                "codeclimate/php-test-reporter": ">=0.2",
                "phpunit/phpunit": "~3.7"
            },
            "type": "library",
            "autoload": {
                "classmap": [
                    "source/robotstxtparser.php"
                ]
            },
            "notification-url": "https://packagist.org/downloads/",
            "license": [
                "MIT"
            ],
            "authors": [
                {
                    "name": "Igor Timoshenkov",
                    "email": "igor.timoshenkov@gmail.com",
                    "role": "creator"
                },
                {
                    "name": "Jan-Petter Gundersen",
                    "email": "jpg@vipnytt.no",
                    "role": "contributor"
                }
            ],
            "description": "PHP class to parse robots.txt rules according to Google, Yandex, W3C and The Web Robots Pages specifications.",
            "homepage": "https://github.com/t1gor/Robots.txt-Parser-Class",
            "keywords": [
                "The Web Robots Pages",
                "W3C",
                "google",
                "parser",
                "robots.txt",
                "yandex"
            ],
            "time": "2018-07-21T20:01:19+00:00"
        },
        {
            "name": "vipnytt/useragentparser",
            "version": "v1.0.4",
            "source": {
                "type": "git",
                "url": "https://github.com/VIPnytt/UserAgentParser.git",
                "reference": "c5a6718a57088e0d45c2e36f09efabc4e008bd8c"
            },
            "dist": {
                "type": "zip",
                "url": "https://api.github.com/repos/VIPnytt/UserAgentParser/zipball/c5a6718a57088e0d45c2e36f09efabc4e008bd8c",
                "reference": "c5a6718a57088e0d45c2e36f09efabc4e008bd8c",
                "shasum": ""
            },
            "require": {
                "php": "^5.5 || ^7.0"
            },
            "require-dev": {
                "phpunit/phpunit": "^4.8.35 || ^5.7 || ^6.5"
            },
            "type": "library",
            "autoload": {
                "psr-4": {
                    "vipnytt\\": "src/"
                }
            },
            "notification-url": "https://packagist.org/downloads/",
            "license": [
                "MIT"
            ],
            "authors": [
                {
                    "name": "VIP nytt AS",
                    "email": "support@vipnytt.no",
                    "role": "Owner"
                },
                {
                    "name": "Jan-Petter Gundersen",
                    "email": "jpg@vipnytt.no",
                    "role": "Developer"
                }
            ],
            "description": "User-Agent parser for robot rule sets",
            "homepage": "https://github.com/VIPnytt/UserAgentParser",
            "keywords": [
                "REP",
                "Robots Exclusion Protocol",
                "Robots meta tag",
                "crawler",
                "robot",
                "robots.txt",
                "spider",
                "user-agent",
                "useragent",
                "x-robots-tag"
            ],
            "time": "2017-12-17T14:23:27+00:00"
        }
    ],
    "packages-dev": [],
    "aliases": [],
    "minimum-stability": "stable",
    "stability-flags": {
        "t1gor/robots-txt-parser": 20
    },
    "prefer-stable": false,
    "prefer-lowest": false,
    "platform": [],
    "platform-dev": []
}
