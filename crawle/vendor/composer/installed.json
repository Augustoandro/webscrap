[
    {
        "name": "t1gor/robots-txt-parser",
        "version": "dev-master",
        "version_normalized": "9999999-dev",
        "source": {
            "type": "git",
            "url": "https://github.com/t1gor/Robots.txt-Parser-Class.git",
            "reference": "7ff08da5625fb4f72d17b1528c60aadb184e9e68"
        },
        "dist": {
            "type": "zip",
            "url": "https://api.github.com/repos/t1gor/Robots.txt-Parser-Class/zipball/7ff08da5625fb4f72d17b1528c60aadb184e9e68",
            "reference": "7ff08da5625fb4f72d17b1528c60aadb184e9e68",
            "shasum": ""
        },
        "require": {
            "ext-mbstring": "*",
            "php": ">=5.5.0",
            "vipnytt/useragentparser": "^1.0"
        },
        "require-dev": {
            "codeclimate/php-test-reporter": ">=0.2",
            "phpunit/phpunit": "~3.7"
        },
        "time": "2018-07-21T20:01:19+00:00",
        "type": "library",
        "installation-source": "source",
        "autoload": {
            "classmap": [
                "source/robotstxtparser.php"
            ]
        },
        "notification-url": "https://packagist.org/downloads/",
        "license": [
            "MIT"
        ],
        "authors": [
            {
                "name": "Igor Timoshenkov",
                "email": "igor.timoshenkov@gmail.com",
                "role": "creator"
            },
            {
                "name": "Jan-Petter Gundersen",
                "email": "jpg@vipnytt.no",
                "role": "contributor"
            }
        ],
        "description": "PHP class to parse robots.txt rules according to Google, Yandex, W3C and The Web Robots Pages specifications.",
        "homepage": "https://github.com/t1gor/Robots.txt-Parser-Class",
        "keywords": [
            "The Web Robots Pages",
            "W3C",
            "google",
            "parser",
            "robots.txt",
            "yandex"
        ]
    },
    {
        "name": "vipnytt/useragentparser",
        "version": "v1.0.4",
        "version_normalized": "1.0.4.0",
        "source": {
            "type": "git",
            "url": "https://github.com/VIPnytt/UserAgentParser.git",
            "reference": "c5a6718a57088e0d45c2e36f09efabc4e008bd8c"
        },
        "dist": {
            "type": "zip",
            "url": "https://api.github.com/repos/VIPnytt/UserAgentParser/zipball/c5a6718a57088e0d45c2e36f09efabc4e008bd8c",
            "reference": "c5a6718a57088e0d45c2e36f09efabc4e008bd8c",
            "shasum": ""
        },
        "require": {
            "php": "^5.5 || ^7.0"
        },
        "require-dev": {
            "phpunit/phpunit": "^4.8.35 || ^5.7 || ^6.5"
        },
        "time": "2017-12-17T14:23:27+00:00",
        "type": "library",
        "installation-source": "dist",
        "autoload": {
            "psr-4": {
                "vipnytt\\": "src/"
            }
        },
        "notification-url": "https://packagist.org/downloads/",
        "license": [
            "MIT"
        ],
        "authors": [
            {
                "name": "VIP nytt AS",
                "email": "support@vipnytt.no",
                "role": "Owner"
            },
            {
                "name": "Jan-Petter Gundersen",
                "email": "jpg@vipnytt.no",
                "role": "Developer"
            }
        ],
        "description": "User-Agent parser for robot rule sets",
        "homepage": "https://github.com/VIPnytt/UserAgentParser",
        "keywords": [
            "REP",
            "Robots Exclusion Protocol",
            "Robots meta tag",
            "crawler",
            "robot",
            "robots.txt",
            "spider",
            "user-agent",
            "useragent",
            "x-robots-tag"
        ]
    }
]
